# Text Autocompletion with Hugging Face Transformers
This repository demonstrates how to use the HuggingFace Transformers library to implement text autocompletion in a Jupyter Notebook environment.

## Getting Started
### Prerequisites
- Python 3.6 or higher
- Jupyter Notebook
- HuggingFace Transformers library

### Installation
1. Clone this repository:
```bash
git clone https://github.com/shaadclt/TextAutocomplete-HuggingFace.git
```

2. Install the required dependencies:
```bash
pip install transformers
```

### Usage
1. Launch Jupyter Notebook:
Open the **autocomplete_huggingface.ipynb** notebook.
2. Follow the instructions in the notebook to see text autocompletion in action.

### Model Used
We use the **pszemraj/opt-350m-email-generation** model for text autocompletion. This model is fine-tuned on a large dataset and is capable of generating coherent text based on prompts.

### License
This project is licensed under the MIT License - see the LICENSE file for details.

### Acknowledgments
1. HuggingFace for providing the Transformers library.
2. Authors of the **pszemraj/opt-350m-email-generation** model.
